import OpenAI from 'openai';
import { loggingService } from './loggingService.js';
import { 
  getSystemPrompt, 
  getModelTemperature, 
  getModelMaxTokens 
} from '../config/modelPromptStrategies.js';
import dotenv from 'dotenv';
import { fileURLToPath } from 'url';
import { dirname, join } from 'path';

// åŠ è½½ç¯å¢ƒå˜é‡
const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);
dotenv.config({ path: join(__dirname, '../../.env') });

// åˆå§‹åŒ–OpenRouterå®¢æˆ·ç«¯
const openrouter = new OpenAI({
  baseURL: 'https://openrouter.ai/api/v1',
  apiKey: process.env.OPENROUTER_API_KEY,
  defaultHeaders: {
    'HTTP-Referer': process.env.OPENROUTER_SITE_URL || 'https://promptvalar.com',
    'X-Title': process.env.OPENROUTER_APP_NAME || 'PromptValar',
  },
});

// æ¨¡å‹é…ç½®
const MODELS = {
  generation: 'anthropic/claude-3.5-sonnet', // ç”¨äºç”Ÿæˆæç¤ºè¯
  parsing: 'anthropic/claude-3-haiku', // ç”¨äºè§£ææç¤ºè¯ï¼ˆæ›´å¿«æ›´ä¾¿å®œï¼‰
} as const;

/**
 * ä»ç”¨æˆ·æƒ³æ³•ç”Ÿæˆä¸“ä¸šæç¤ºè¯ï¼ˆåŸºäº8è¦ç´ æ¡†æ¶å’Œå¯¼æ¼”å¼æ€ç»´ï¼‰
 * 
 * ä¼˜åŒ–äº®ç‚¹ï¼š
 * 1. æ ¹æ®ç›®æ ‡æ¨¡å‹åŠ¨æ€é€‰æ‹©ä¸“ç”¨System Prompt
 * 2. å¼ºåˆ¶è¦æ±‚8è¦ç´ ç»“æ„åŒ–è¾“å‡º
 * 3. é’ˆå¯¹ä¸åŒæ¨¡å‹è°ƒæ•´ç”Ÿæˆå‚æ•°ï¼ˆtemperature, max_tokensï¼‰
 * 4. å¼•å¯¼AIåƒå¯¼æ¼”ä¸€æ ·æ€è€ƒï¼Œè€Œéå…³é”®è¯ç”Ÿæˆå™¨
 */
export async function generatePromptFromIdea(
  idea: string,
  targetModel: string,
  style: string,
  userId?: string
): Promise<{ prompt: string; structured: StructuredPromptData; logId: string }> {
  const startTime = Date.now();
  
  // ğŸ¯ æ ¸å¿ƒä¼˜åŒ–ï¼šæ ¹æ®æ¨¡å‹é€‰æ‹©ä¸“é—¨çš„System Prompt
  const systemPrompt = getSystemPrompt(targetModel, style);
  
  // æ„å»ºç”¨æˆ·æ¶ˆæ¯ï¼Œå¼•å¯¼AIè¿›è¡Œç»“æ„åŒ–æ€è€ƒ
  const userMessage = `ç”¨æˆ·åˆ›æ„æƒ³æ³•ï¼š${idea}

ç›®æ ‡æ¨¡å‹ï¼š${targetModel}
æœŸæœ›é£æ ¼ï¼š${style}

è¯·æŒ‰ç…§8è¦ç´ æ¡†æ¶ï¼ˆSubject, Setting, Action, Camera, Style, Audio, Timeline, Constraintsï¼‰ç”Ÿæˆä¸“ä¸šçš„æç¤ºè¯ã€‚

ç‰¹åˆ«æ³¨æ„ï¼š
${targetModel === 'sora' ? '- è¿™æ˜¯è§†é¢‘ç”Ÿæˆï¼Œéœ€è¦è€ƒè™‘æ—¶é—´è½´å’ŒåŠ¨ä½œè¿è´¯æ€§\n- æ·»åŠ ç‰©ç†çº¦æŸä»¥ç¡®ä¿çœŸå®æ„Ÿ' : ''}
${targetModel === 'veo' ? '- è¿™æ˜¯è§†é¢‘+éŸ³é¢‘ç”Ÿæˆï¼Œå¿…é¡»è¯¦ç»†æè¿°éŸ³é¢‘å…ƒç´ ï¼ˆå¯¹è¯/éŸ³æ•ˆ/é…ä¹ï¼‰\n- è€ƒè™‘å¤šåœºæ™¯æ—¶å¯ä½¿ç”¨timeline' : ''}
${targetModel === 'nano_banana' ? '- ä½¿ç”¨æ‘„å½±å¸ˆè§†è§’ï¼Œæè¿°åœºæ™¯è€Œéç½—åˆ—å…³é”®è¯\n- åŒ…å«ç›¸æœºå’Œé•œå¤´ç»†èŠ‚' : ''}
${targetModel === 'seedream' ? '- è¿™æ˜¯å›¾åƒç¼–è¾‘ï¼Œéœ€è¦ç²¾å‡†çš„æŒ‡ä»¤\n- å¼ºè°ƒè´¨é‡å’Œç»†èŠ‚ä¿ç•™' : ''}`;

  try {
    const completion = await openrouter.chat.completions.create({
      model: MODELS.generation,
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: userMessage },
      ],
      // ğŸ¯ æ ¹æ®æ¨¡å‹ç±»å‹åŠ¨æ€è°ƒæ•´å‚æ•°
      temperature: getModelTemperature(targetModel),
      max_tokens: getModelMaxTokens(targetModel),
      response_format: { type: 'json_object' },
    });

    const content = completion.choices[0].message.content;
    if (!content) {
      throw new Error('No response from AI model');
    }

    const result = JSON.parse(content);
    
    // éªŒè¯å¿…éœ€å­—æ®µæ˜¯å¦å­˜åœ¨
    if (!result.prompt || !result.structured) {
      throw new Error('Invalid response format from AI');
    }
    
    // ç¡®ä¿structuredå¯¹è±¡åŒ…å«æ‰€æœ‰å¿…éœ€çš„åŸºç¡€å­—æ®µ
    const structured: StructuredPromptData = {
      subject: result.structured.subject || '',
      setting: result.structured.setting || '',
      action: result.structured.action || '',
      shotType: result.structured.shotType || '',
      cameraMovement: result.structured.cameraMovement,
      style: result.structured.style,
      lighting: result.structured.lighting || '',
      audio: result.structured.audio,
      timeline: result.structured.timeline,
      constraints: result.structured.constraints,
      composition: result.structured.composition || '',
      mood: result.structured.mood || [],
      parameters: result.structured.parameters || '',
    };
    
    const generationTime = Date.now() - startTime;
    
    // è®°å½•ç”Ÿæˆæ—¥å¿—
    const logId = await loggingService.logGeneration({
      userId,
      inputIdea: idea,
      inputModel: targetModel,
      inputStyle: style,
      outputPrompt: result.prompt,
      outputStructured: structured,
      generationTime,
      tokensUsed: completion.usage?.total_tokens || 0,
      aiModelUsed: MODELS.generation,
    });
    
    return {
      prompt: result.prompt,
      structured,
      logId,
    };
  } catch (error) {
    console.error('OpenRouter API error:', error);
    throw new Error('Failed to generate prompt. Please try again.');
  }
}

/**
 * è§£æç°æœ‰æç¤ºè¯ä¸ºç»“æ„åŒ–ç»„ä»¶
 */
export async function parsePromptToStructured(
  promptText: string,
  targetModel: string
): Promise<StructuredPromptData> {
  const systemPrompt = `You are a prompt analysis expert. Parse the given ${targetModel} prompt into structured components.

Extract and return JSON with these fields:
- subject: Main subject/character
- action: What's happening
- setting: Location/environment
- shotType: Camera angle/framing
- lighting: Lighting conditions
- composition: Composition details
- mood: Array of mood descriptors
- parameters: Model-specific parameters (if any)

If a component is not present in the prompt, use an empty string or empty array.`;

  try {
    const completion = await openrouter.chat.completions.create({
      model: MODELS.parsing,
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: promptText },
      ],
      temperature: 0.3,
      response_format: { type: 'json_object' },
    });

    const content = completion.choices[0].message.content;
    if (!content) {
      throw new Error('No response from AI model');
    }

    return JSON.parse(content);
  } catch (error) {
    console.error('OpenRouter API error:', error);
    throw new Error('Failed to parse prompt. Please try again.');
  }
}

/**
 * è·å–æç¤ºè¯æ”¹è¿›å»ºè®®
 */
export async function getSuggestions(
  promptText: string,
  targetModel: string
): Promise<string[]> {
  const systemPrompt = `You are a prompt improvement expert for ${targetModel}.

Analyze the given prompt and provide 3-5 specific suggestions for improvement.

Return your response as JSON with a "suggestions" array containing string items.`;

  try {
    const completion = await openrouter.chat.completions.create({
      model: MODELS.parsing,
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: promptText },
      ],
      temperature: 0.5,
      response_format: { type: 'json_object' },
    });

    const content = completion.choices[0].message.content;
    if (!content) {
      throw new Error('No response from AI model');
    }

    const result = JSON.parse(content);
    return result.suggestions || [];
  } catch (error) {
    console.error('OpenRouter API error:', error);
    throw new Error('Failed to get suggestions. Please try again.');
  }
}

// æ—¶é—´è½´åœºæ™¯ç±»å‹
export interface TimelineScene {
  start: number; // å¼€å§‹æ—¶é—´ï¼ˆç§’ï¼‰
  end: number; // ç»“æŸæ—¶é—´ï¼ˆç§’ï¼‰
  description: string; // åœºæ™¯æè¿°
}

// ç»“æ„åŒ–æç¤ºè¯æ•°æ®ç±»å‹ (8è¦ç´ æ¡†æ¶)
// åŸºäºå¯¼æ¼”å¼è§†é¢‘ç”Ÿæˆä¼˜åŒ–ç†è®º
export interface StructuredPromptData {
  // è¦ç´ 1: Subject - ä¸»é¢˜
  subject: string;
  
  // è¦ç´ 2: Setting - ç¯å¢ƒ
  setting: string;
  
  // è¦ç´ 3: Action - åŠ¨ä½œ
  action: string;
  
  // è¦ç´ 4: Camera - æ‘„å½±
  shotType: string;
  cameraMovement?: string;
  
  // è¦ç´ 5: Style - è§†è§‰é£æ ¼
  style?: string;
  lighting: string;
  
  // è¦ç´ 6: Audio - éŸ³æ•ˆï¼ˆVeoç‰¹åˆ«é‡è¦ï¼‰
  audio?: string;
  
  // è¦ç´ 7: Timeline - æ—¶é—´è½´ï¼ˆå¤šåœºæ™¯è§†é¢‘ï¼‰
  timeline?: TimelineScene[];
  
  // è¦ç´ 8: Constraints - çº¦æŸæ¡ä»¶
  constraints?: string;
  
  // ä¼ ç»Ÿå­—æ®µï¼ˆä¿ç•™å…¼å®¹æ€§ï¼‰
  composition: string;
  mood: string[];
  parameters: string;
}

